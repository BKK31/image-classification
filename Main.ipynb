{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, BatchNormalization, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './Dataset'\n",
    "\n",
    "# Load dataset from directory\n",
    "dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir,image_size=(150,150),batch_size=32,label_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "class_names = dataset.class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training and testing\n",
    "train_size = 0.8\n",
    "train_ds = dataset.take(int(len(dataset) * train_size))\n",
    "test_ds = dataset.skip(int(len(dataset) * train_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the train dataset further into train and validation\n",
    "val_size = int(0.2 *  len(train_ds))\n",
    "val_ds = train_ds.take(val_size)\n",
    "train_ds = train_ds.skip(val_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add this data augmentation layer\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "    tf.keras.layers.RandomRotation(0.2),\n",
    "    tf.keras.layers.RandomZoom(0.2),\n",
    "    tf.keras.layers.RandomContrast(0.1)\n",
    "])\n",
    "\n",
    "# Apply data augmentation to the dataset\n",
    "train_ds = train_ds.map(lambda x, y: (data_augmentation(x, training=True), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prefetch for performance\n",
    "train_ds = train_ds.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "test_ds = test_ds.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_to_numpy(dataset):\n",
    "    images, labels = [], []\n",
    "    for batch_images, batch_labels in dataset:\n",
    "        images.append(batch_images.numpy())\n",
    "        labels.append(batch_labels.numpy())\n",
    "    return np.concatenate(images), np.concatenate(labels)\n",
    "\n",
    "# Extract training and testing data\n",
    "x_train, y_train = dataset_to_numpy(train_ds)\n",
    "x_test, y_test = dataset_to_numpy(test_ds)\n",
    "\n",
    "x_train=x_train/255.0\n",
    "x_test=x_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    # Block 1\n",
    "    Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(150, 150, 3)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "\n",
    "    # Block 2\n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "\n",
    "    # Fully Connected Layers\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(17, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy', optimizer=optim, metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train, epochs=25, batch_size=64, validation_data=val_ds)\n",
    "model.save('trained.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training and validation accuracy/loss\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a random image from the test set for prediction\n",
    "idx = random.randint(0, len(x_test) - 1)\n",
    "test_image = x_test[idx]\n",
    "true_class_idx = np.argmax(y_test[idx])  # True class index\n",
    "true_class_name = class_names[true_class_idx]\n",
    "\n",
    "plt.imshow(test_image)\n",
    "plt.axis('off')  # Hide axis for a cleaner view\n",
    "# plt.title(f\"Actual: {true_class_name}\")\n",
    "plt.show()\n",
    "\n",
    "# Predict the class for the test image\n",
    "predicted_prob = model.predict(test_image.reshape(1, 150,150, 3))  # Reshape the image\n",
    "predicted_class_idx = np.argmax(predicted_prob)  # Get the predicted class index\n",
    "predicted_class_name = class_names[predicted_class_idx]\n",
    "\n",
    "# Display predicted and actual class names\n",
    "print(f\"Predicted class: {predicted_class_name}\")\n",
    "print(f\"Actual class: {true_class_name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (garuda)",
   "language": "python",
   "name": "garuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
